{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import common_utils as utils\n",
    "import wandb\n",
    "from collections import defaultdict\n",
    "import torch_pruning as tp\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "print(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you change these if you choose a different checkpoint!!\n",
    "checkpoint_path = \"base_model/checkpoint_6.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))\n",
    "     ])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.FER2013(root='./', split=\"train\",\n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.FER2013(root='./', split=\"test\",\n",
    "                                       transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(\n",
    "            \"Sparsity in {0}: {1:.2f}%\".format(name,\n",
    "                100. * float(torch.sum(param == 0))\n",
    "                / float(param.nelement())\n",
    "            ), \"\\nParam Element Count: {0}\\n\".format(param.nelement())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114cddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA Reserved Memory: \", torch.cuda.memory_reserved())\n",
    "layer_sensitivity = defaultdict(list)\n",
    "example_inputs = torch.randn(1, 1, 96, 96).to(utils.device)\n",
    "imp = tp.importance.GroupMagnitudeImportance(p=2) \n",
    "\n",
    "def get_prunable_modules(model):\n",
    "    prunable_modules = []\n",
    "    for name, module in model.named_children():\n",
    "        if (isinstance(module, nn.MaxPool2d) or (isinstance(module, nn.Linear) and module.out_features == 7)):\n",
    "            continue\n",
    "        else:\n",
    "            prunable_modules.append((name, module))\n",
    "    return prunable_modules\n",
    "pruned_model = utils.BaseModel()\n",
    "num_prunable_params = len(get_prunable_modules(pruned_model))\n",
    "\n",
    "for param_ind in range(num_prunable_params):\n",
    "    for i in range(10, 100, 10):\n",
    "        print(\"CUDA Reserved Memory: \", torch.cuda.memory_reserved())\n",
    "        sparsity = i / 100\n",
    "        pruned_model = utils.BaseModel()\n",
    "        # Checking training graphs this is around test/loss starts climbing (though accuracy still improves)\n",
    "        # Make sure you change these if you choose a different checkpoint!!!!!!!\n",
    "        pruned_model.load_state_dict(torch.load(checkpoint_path))\n",
    "        pruned_model.to(utils.device)\n",
    "        module_name, module = get_prunable_modules(pruned_model)[param_ind]\n",
    "        print(\"Pruning {0} with sparsity {1}\".format(module_name, sparsity))\n",
    "        pruner = tp.pruner.BasePruner( # We can always choose BasePruner if sparse training is not required.\n",
    "            pruned_model,\n",
    "            example_inputs,\n",
    "            importance=imp,\n",
    "            pruning_ratio=0.0,\n",
    "            pruning_ratio_dict = {module: sparsity}, # customized pruning ratios for layers or blocks\n",
    "            # ignored_layers=ignored_layers,\n",
    "            round_to=1,\n",
    "        )\n",
    "        base_macs, base_nparams = tp.utils.count_ops_and_params(pruned_model, example_inputs)\n",
    "        # tp.utils.print_tool.before_pruning(pruned_model) # or print(model)\n",
    "        pruner.step()\n",
    "        # tp.utils.print_tool.after_pruning(pruned_model) # or print(model), this util will show the difference before and after pruning\n",
    "        macs, nparams = tp.utils.count_ops_and_params(pruned_model, example_inputs)\n",
    "        print(f\"MACs: {base_macs/1e9} G -> {macs/1e9} G, #Params: {base_nparams/1e6} M -> {nparams/1e6} M\")\n",
    "\n",
    "        loss, acc = utils.test(pruned_model, testloader)\n",
    "        layer_sensitivity[module_name].append((loss, acc))\n",
    "        print(\"Post Pruning Loss: {0} Accuracy: {1}\\n\".format(loss, acc))\n",
    "        del pruned_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "with open(\"sensitivity.pkl\", \"wb\") as file:\n",
    "    pickle.dump(layer_sensitivity, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6327fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sensitivity.pkl\", \"rb\") as file:\n",
    "    layer_sensitivity = pickle.load(file)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(30, 12))\n",
    "\n",
    "\n",
    "for (key, values) in layer_sensitivity.items():\n",
    "    losses = [e[0] for e in values]\n",
    "    acc = [e[1] for e in values]\n",
    "\n",
    "    axs[0].plot(list(range(10, 100, 10)), losses, label = key)\n",
    "    axs[1].plot(list(range(10, 100, 10)), acc, label=key)\n",
    "\n",
    "axs[0].set_title(\"Loss Vs Pruning Ratio\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].set_xlabel(\"Pruning Ratio\")\n",
    "\n",
    "axs[1].set_title(\"Accuracy Vs Pruning Ratio\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Pruning Ratio\")\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"images/sensitivity_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2a3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_threshold = 50\n",
    "layer_to_pruning_threshold = {}\n",
    "\n",
    "for (key, values) in layer_sensitivity.items():\n",
    "    layer_to_pruning_threshold[key] = 0\n",
    "    losses = [e[0] for e in values]\n",
    "    acc = [e[1] for e in values]\n",
    "    for i in range(len(acc)):\n",
    "        if acc[i] > accuracy_threshold:\n",
    "            layer_to_pruning_threshold[key] = i / 10\n",
    "print(layer_to_pruning_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = utils.BaseModel()\n",
    "pruned_model.load_state_dict(torch.load(\"base_model/checkpoint_6.pth\"))\n",
    "pruned_model.to(utils.device)\n",
    "example_inputs = torch.randn(1, 1, 96, 96).to(utils.device)\n",
    "\n",
    "\n",
    "# 1. Importance criterion, here we calculate the L2 Norm of grouped weights as the importance score\n",
    "imp = tp.importance.GroupMagnitudeImportance(p=2) \n",
    "\n",
    "# 2. Initialize a pruner with the model and the importance criterion\n",
    "ignored_layers = []\n",
    "for m in pruned_model.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 7:\n",
    "        ignored_layers.append(m) # DO NOT prune the final classifier!\n",
    "\n",
    "pruning_ratio_dict = {}\n",
    "for (key, value) in layer_to_pruning_threshold.items():\n",
    "    pruning_ratio_dict[eval(\"pruned_model.\" + key)] = value\n",
    "\n",
    "pruner = tp.pruner.BasePruner( # We can always choose BasePruner if sparse training is not required.\n",
    "    pruned_model,\n",
    "    example_inputs,\n",
    "    importance=imp,\n",
    "    pruning_ratio=0.0, \n",
    "    pruning_ratio_dict=pruning_ratio_dict,\n",
    "    ignored_layers=ignored_layers,\n",
    "    round_to=1,\n",
    ")\n",
    "\n",
    "# 3. Prune the model\n",
    "base_macs, base_nparams = tp.utils.count_ops_and_params(pruned_model, example_inputs)\n",
    "tp.utils.print_tool.before_pruning(pruned_model) # or print(model)\n",
    "pruner.step()\n",
    "tp.utils.print_tool.after_pruning(pruned_model) # or print(model), this util will show the difference before and after pruning\n",
    "macs, nparams = tp.utils.count_ops_and_params(pruned_model, example_inputs)\n",
    "print(f\"MACs: {base_macs/1e9} G -> {macs/1e9} G, #Params: {base_nparams/1e6} M -> {nparams/1e6} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b00983",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = utils.test(pruned_model, testloader)\n",
    "print(\"Post Pruning Finetuning Loss: {0} Accuracy: {1}\\n\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e14b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"hpml-final\", name=\"Pruned Model Finetuning\")\n",
    "params = utils.TrainingParams()\n",
    "params.lr = 0.00001\n",
    "params.checkpoint = True\n",
    "params.dir_name = \"pruned_model\"\n",
    "params.save_state_dict = False\n",
    "utils.train(run, pruned_model, params, trainloader, testloader, 10)\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
