{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc18132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import common_utils as utils\n",
    "import os\n",
    "print(utils.device)\n",
    "utils.device = \"cpu\" # For quantization we use cpu\n",
    "print(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4503e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))\n",
    "     ])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.FER2013(root='./', split=\"train\",\n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.FER2013(root='./', split=\"test\",\n",
    "                                       transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa518b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = torch.load(\"pruned_model/checkpoint_1.pth\", weights_only=False, map_location=utils.device)\n",
    "pruned_model.to(utils.device)\n",
    "\n",
    "base_model = utils.BaseModel()\n",
    "base_model.load_state_dict(torch.load(\"base_model/checkpoint_6.pth\", map_location=utils.device))\n",
    "base_model.to(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_base_model = utils.quantize_model(base_model, testloader)\n",
    "quantized_pruned_model = utils.quantize_model(pruned_model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.benchmark_model(base_model, testloader, 100)\n",
    "utils.benchmark_model(quantized_base_model, testloader, 100)\n",
    "utils.benchmark_model(pruned_model, testloader, 100)\n",
    "utils.benchmark_model(quantized_pruned_model, testloader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.test(base_model, testloader))\n",
    "print(utils.test(quantized_base_model, testloader))\n",
    "print(utils.test(pruned_model, testloader))\n",
    "print(utils.test(quantized_pruned_model, testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd02fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_input = torch.randn(1, 1, 96, 96)\n",
    "traced_base_model = torch.jit.trace(base_model, trace_input)\n",
    "trace_pruned_model = torch.jit.trace(pruned_model, trace_input)\n",
    "traced_quantized_base_model = torch.jit.trace(quantized_base_model, trace_input)\n",
    "traced_quantized_pruned_model = torch.jit.trace(quantized_pruned_model, trace_input)\n",
    "torch.jit.save(traced_base_model, os.path.join(\"base_model\", \"jit_traced.pth\"))\n",
    "torch.jit.save(trace_pruned_model, os.path.join(\"pruned_model\", \"jit_traced.pth\"))\n",
    "torch.jit.save(traced_quantized_base_model, os.path.join(\"base_model\", \"jit_traced_quantized.pth\"))\n",
    "torch.jit.save(traced_quantized_pruned_model, os.path.join(\"pruned_model\", \"jit_traced_quantized.pth\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPML_Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
