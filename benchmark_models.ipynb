{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import common_utils as utils\n",
    "import wandb\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "print(utils.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4e1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))\n",
    "     ])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.FER2013(root='./', split=\"train\",\n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.FER2013(root='./', split=\"test\",\n",
    "                                       transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=8)\n",
    "# Use a batchsize of 1 to more accurately model individual frames from camera\n",
    "benchmark_loader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccababd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adejuwon/miniconda3/envs/HPML_Final/lib/python3.12/site-packages/torch/ao/quantization/observer.py:244: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_model = utils.BaseModel()\n",
    "base_model.load_state_dict(torch.load(\"base_model/checkpoint_6.pth\", map_location=utils.device))\n",
    "base_model.to(utils.device)\n",
    "pruned_model = torch.load(\"pruned_model/checkpoint_1.pth\", weights_only=False, map_location=utils.device)\n",
    "pruned_model.to(utils.device)\n",
    "\n",
    "# Just requantize the model instead of loading jit tracse/state dicts.  Time saving\n",
    "# is minimal all things considered.\n",
    "quantized_base_model = utils.quantize_model(base_model, testloader)\n",
    "quantized_pruned_model = utils.quantize_model(pruned_model, testloader)\n",
    "\n",
    "compiled_base_model = copy.deepcopy(base_model)\n",
    "compiled_base_model.compile()\n",
    "compiled_pruned_model = copy.deepcopy(pruned_model)\n",
    "compiled_pruned_model.compile()\n",
    "compiled_quantized_base_model = copy.deepcopy(quantized_base_model)\n",
    "compiled_quantized_base_model.compile()\n",
    "compiled_quantized_pruned_model = copy.deepcopy(quantized_pruned_model)\n",
    "compiled_quantized_pruned_model.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d001d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"base_model\", base_model),\n",
    "    (\"pruned_model\", pruned_model),\n",
    "    (\"quantized_base_model\", quantized_base_model),\n",
    "    (\"quantized_pruned_model\", quantized_pruned_model),\n",
    "    (\"compiled_base_model\", compiled_base_model),\n",
    "    (\"compiled_pruned_model\", compiled_pruned_model),\n",
    "    (\"compiled_quantized_base_model\", compiled_quantized_base_model),\n",
    "    (\"compiled_quantized_pruned_model\", compiled_quantized_pruned_model),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_results = defaultdict(dict)\n",
    "for (name, model) in models:\n",
    "    run = wandb.init(project=\"hpml-final\", name=\"{0} Benchmark\".format(name))\n",
    "    loss, acc = utils.test(model, testloader)\n",
    "    benchmark_results[name][\"test_loss\"] = loss\n",
    "    benchmark_results[name][\"test_acc\"] = acc\n",
    "    utils.benchmark_model(model, benchmark_loader, 200) # warm start\n",
    "    benchmark_results[name][\"benchmark\"] = utils.benchmark_model(model, benchmark_loader, 200)\n",
    "    run.log(\n",
    "        {\n",
    "            \"test/loss\" : loss,\n",
    "            \"test/acc\" : acc,\n",
    "            \"benchmark/images\" : benchmark_results[name][\"benchmark\"][\"total_images\"],\n",
    "            \"benchmark/total_time\" : benchmark_results[name][\"benchmark\"][\"total_time\"],\n",
    "            \"benchmark/mean_time\" : benchmark_results[name][\"benchmark\"][\"mean_time\"],\n",
    "            \"benchmark/mean_fps\" : benchmark_results[name][\"benchmark\"][\"mean_fps\"],\n",
    "        }\n",
    "    )\n",
    "    run.finish()\n",
    "with open(\"benchmark_results.pkl\", \"wb\") as file:\n",
    "    pickle.dump(benchmark_results, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9911d9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"benchmark_results.pkl\", \"rb\") as file:\n",
    "    benchmark_results = pickle.load(file)\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(30, 12))\n",
    "plt.figure(figsize=(10, 6))\n",
    "key_order = [\n",
    "    \"base_model\",\n",
    "    \"quantized_base_model\",\n",
    "    \"pruned_model\",\n",
    "    \"quantized_pruned_model\",\n",
    "    \"compiled_base_model\",\n",
    "    \"compiled_quantized_base_model\",\n",
    "    \"compiled_pruned_model\",\n",
    "    \"compiled_quantized_pruned_model\"\n",
    "]\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "mean_times = []\n",
    "mean_frames_per_second = []\n",
    "\n",
    "for key in key_order:\n",
    "    test_losses.append(benchmark_results[key][\"test_loss\"])\n",
    "    test_accuracies.append(benchmark_results[key][\"test_acc\"])\n",
    "    mean_times.append(benchmark_results[key][\"benchmark\"][\"mean_time\"])\n",
    "    mean_frames_per_second.append(benchmark_results[key][\"benchmark\"][\"mean_fps\"])\n",
    "\n",
    "\n",
    "plt.plot(key_order[:4], test_accuracies[:4])\n",
    "plt.title(\"Test Accuracies Per Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/benchmark_accuracies.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(key_order[:4], test_losses[:4])\n",
    "plt.title(\"Test Loss Per Model\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/benchmark_losses.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(key_order[:4], mean_times[:4], label=\"Uncompiled\")\n",
    "plt.plot(key_order[:4], mean_times[4:], label=\"Compiled\")\n",
    "plt.title(\"Mean Inference Time Per Model\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/benchmark_inference_times.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(key_order[:4], mean_frames_per_second[:4],label=\"Uncompiled\")\n",
    "plt.plot(key_order[:4], mean_frames_per_second[4:], label=\"Compiled\")\n",
    "plt.title(\"Mean FPS(estimated) Per Model\")\n",
    "plt.ylabel(\"FPS\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/benchmark_fps.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5897d6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'base_model': {'test_loss': 0.08092272355550509,\n",
       "              'test_acc': 57.32794650320424,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 12.278436183929443,\n",
       "               'mean_time': 0.06108674718372857,\n",
       "               'mean_fps': 16.370162860240917}},\n",
       "             'pruned_model': {'test_loss': 0.07692547515761258,\n",
       "              'test_acc': 56.85427695736974,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 1.0372767448425293,\n",
       "               'mean_time': 0.005160580820112086,\n",
       "               'mean_fps': 193.7766377192946}},\n",
       "             'quantized_base_model': {'test_loss': 0.0814350373019545,\n",
       "              'test_acc': 56.96572861521315,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 2.9115970134735107,\n",
       "               'mean_time': 0.01448555728096274,\n",
       "               'mean_fps': 69.0342788063959}},\n",
       "             'quantized_pruned_model': {'test_loss': 0.07708757794411543,\n",
       "              'test_acc': 56.32488158261354,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 0.7272529602050781,\n",
       "               'mean_time': 0.003618173931368548,\n",
       "               'mean_fps': 276.3825119987411}},\n",
       "             'compiled_base_model': {'test_loss': 0.08092272401221386,\n",
       "              'test_acc': 57.32794650320424,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 39.64514780044556,\n",
       "               'mean_time': 0.19723954129574903,\n",
       "               'mean_fps': 5.069977315048401}},\n",
       "             'compiled_pruned_model': {'test_loss': 0.07692547449330893,\n",
       "              'test_acc': 56.85427695736974,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 1.3276793956756592,\n",
       "               'mean_time': 0.006605370127739598,\n",
       "               'mean_fps': 151.3919705726175}},\n",
       "             'compiled_quantized_base_model': {'test_loss': 0.0814350373019545,\n",
       "              'test_acc': 56.96572861521315,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 2.5836241245269775,\n",
       "               'mean_time': 0.012853851365805859,\n",
       "               'mean_fps': 77.79769436732599}},\n",
       "             'compiled_quantized_pruned_model': {'test_loss': 0.07708757794411543,\n",
       "              'test_acc': 56.32488158261354,\n",
       "              'benchmark': {'total_images': 201,\n",
       "               'total_time': 0.7953286170959473,\n",
       "               'mean_time': 0.003956858791522125,\n",
       "               'mean_fps': 252.72572327892445}}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acdbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, model) in models: # do this after because we can't pickle these apparently\n",
    "    benchmark_results[name][\"profile\"] = utils.profile_model(model, benchmark_loader, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd12362",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"profile_results.txt\", \"w\") as file:\n",
    "    for (name, model) in models:\n",
    "        file.write(\"*************************\\n\")\n",
    "        file.write(name + \"\\n\")\n",
    "        file.write(\"*************************\\n\")\n",
    "        file.write(benchmark_results[name][\"profile\"].key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=30))\n",
    "        file.write(benchmark_results[name][\"profile\"].key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=30))\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faecc488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPML_Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
